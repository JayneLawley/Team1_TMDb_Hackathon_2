# ![CI logo](https://codeinstitute.s3.amazonaws.com/fullstack/ci_logo_small.png)

# Project: Movie Success Analysis

## Dataset Content
* This [dataset](https://www.kaggle.com/datasets/tmdb/tmdb-movie-metadata) has the following characteristics:# TMDb Movie Dataset

**TMDb Movie Dataset** is a collection of data for 4,803 films from The Movie Database (TMDb), combining two CSV files (movies and credits) with information such as budget, revenue, genres, cast, crew, runtime, languages, popularity, and user ratings. This project uses the dataset to explore the drivers of box-office performance and to build features and models that predict revenue.

## Business Requirements
* Create a model that will predict the revenue generated by a movie so production companies can understand if their movie will be successful or unsuccessful.
* Build a classification model to predict whether a film will achieve "High Performer" status (revenue above the median) based on production attributes, financial metrics, and team composition.
* Help production companies understand the key success drivers that determine whether a film will be commercially successful.
* Develop genre-specific dashboards that provide tailored insights and success factors for different film categories.

## Hypothesis Tested

* **Hypothesis 1:** Movies that get a lot of thumbs up (or votes average) are likely to be an indicator of movie success 
* **Hypothesis 2:** Movie success is influenced  by Cast
* **Hypothesis 3:** Movie success is influenced by Budget
* **Hypothesis 4:** Action movies have a higher likelihood of box office success
* **Hypothesis 5:** English Language movies are more likely to get higher ratings
* **Hypothesis 6:** There will be a difference in popularity between the genres

## Test used and why
**Pearson Correlation (H1, H3)** – Measures the linear relationship strength between two continuous variables. Used to test whether ratings and revenue move together, and if budget predicts revenue. Visualised with regression plots to show trend lines and confidence intervals

**Mann-Whitney U Test (H1, H2, H4)** – Non-parametric alternative to t-tests that is robust to skewed distributions and outliers (common in financial data like revenue, profit, and ROI). Includes two-sided tests for statistical significance and one-sided directional checks to confirm effect direction

**Kruskal-Wallis H-Test (H2, H3)** – Non-parametric test comparing medians across three or more independent groups (e.g., actor frequency categories: Emerging, Established, Recurring; budget quartiles). Appropriate when data is non-normally distributed

**Welch's T-Test (H5)** – Compares means between two independent groups without assuming equal variances. Used to test whether English and Non-English movie ratings differ significantly

**Spearman Correlation (H2)** – Non-parametric correlation coefficient suitable for ordinal or skewed continuous data. Used to assess whether actor frequency correlates with success metrics across Revenue, ROI, and Ratings

**Hypothesis 6** Genre Shapes Popularity: Tested using the Kruskal-Wallis H-test and post-hoc pairwise Mann-Whitney U tests. 

 **Key Findings:**
 - Hypothesis 1 – Ratings Matter, But Weakly: Statistically significant difference between high (7–10) and low (0–7) rated movies (p < 0.001). High-rated films average £90.9M revenue vs. £64.2M for low-rated, but weak correlation (r = ~0.3). Popularity correlates more strongly with revenue than ratings alone.
- Hypothesis 2 – Cast Matters: Emerging Actors Outperform: Films with emerging casts outperform established/recurring actors across revenue, ROI, and ratings (all p < 0.001). Top individual actors (Tom Cruise, Tom Hanks, Ben Stiller) average £240M+ per film. Limited cast data warrants caution; exploratory findings only.
- Hypothesis 3 – Budget Strongly Predicts Revenue: Strong positive Pearson correlation (r = 0.731, p < 0.001); budget explains ~53% of revenue variance. Higher-budget films show best median ROI (2.17x for high-budget vs. 1.50x for low-budget, p < 0.001). Trend holds in log-scaled sensitivity analysis; exceptions exist (some low-budget films achieve exceptional success).
- Hypothesis 4 – Action Movies Show Higher Profit Potential: Statistically significant difference in both revenue and profit (both p < 0.001, one-sided test). Action films achieve higher mean and median profits, showing "high risk, high reward" pattern. Success rate similar to non-action, but when action films succeed, they generate substantially higher revenue.
- Hypothesis – Non-English Films Rate Slightly Higher (H5 Not Supported): Significant difference found (t = -5.66, p < 0.001), but in opposite direction: non-English movies average 6.49 rating vs. 6.07 for English films. Japanese (7.05) and Italian (7.03) top ratings; English dominates by volume (4,505 of ~4,850 films).
- Hypothesis 6 – Genre Shapes Popularity: Non-parametric tests confirmed significant differences in popularity between genres (p < 0.001). Action, Adventure, Sci-Fi, and Animation consistently ranked highest, while Drama, Music, and Documentary trailed behind. These differences are statistically and practically meaningful, showing that audience interest varies strongly by genre.



- This dataset is split between 2 different CSV files:
 
| File                     | Size   | Columns | Rows |
|--------------------------|--------|---------|------|
| `tmdb_5000_credits.csv`  | 40.04MB| 3       | 4803 |
| `tmdb_5000_movies.csv`   | 5.7MB  | 20      | 4803 |

The dataset has many different variables that relate to the movie ranging from cast and genre to budget and revenue. We can use these variables to gain an understanding of each movie. 

## Folder Structure
![alt text](image-1.png)



## Key files
| File/Folder                            | Purpose/Description                                          |
|----------------------------------------|--------------------------------------------------------------|
| `Data/RAW/tmdb_5000_credits.csv`       | Raw credits data from TMDb                                   |
| `Data/RAW/tmdb_5000_movies.csv`        | Raw movies data from TMDb                                    |
| `Data/PROCESSED/movies_ready_for_EDA.csv` | Cleaned and feature-engineered dataset for analysis       |
|`jupyter_notebooks/ETL.ipynb`           | Data loading, cleaning, merging, and feature creation        |
| `jupyter_notebooks/EDA.ipynb`          | Exploratory data analysis and hypothesis validation          |
| `dashboard/Team1_TMdb_Hackathon.pbix`  | Power BI dashboard with success drivers and genre insights   |
| `reports/model_predictions_JL.csv`     | Model predictions and risk level classifications             |
| `reports/model_metrics_JL.csv`         | Performance metrics (accuracy, ROC-AUC, precision, recall)   |
| `reports/feature_importance_JL.csv`    | Ranked feature importance scores                             |
| `reports/benchmark_comparison_JL.csv`  | Model performance benchmarked by High Performer status       |
| `requirements.txt`                     | Python dependencies and package versions                     |
| `Procfile`                             | Heroku deployment configuration                              |
| `setup.sh`                             | Environment setup script                                     |
|`README.md`                             | Project documentation                                        |


## Project Plan

* **Data Collection & ETL:** Load and merge raw CSV files from TMDb, handle missing values, and prepare data for analysis
* **Exploratory Data Analysis (EDA):** Visualise distributions and relationships between production features and film performance
* **Feature Engineering:** Transform categorical features, handle missing values, and prepare data for modelling
* **Statistical Testing:** Validate assumptions about which production factors influence success
* **Modelling:** Build and evaluate multiple model approaches to predict film performance
* **Performance Evaluation:** Assess model performance using appropriate metrics for each approach
* **Feature Importance Analysis:** Identify which production attributes are strongest predictors of success across models
* **Dashboard:** Build interactive Power BI Dashboard with one overview dashboard presenting success drivers and an example genre-specific dashboard for detailed genre insights


## Analysis Techniques Used

* **Exploratory Data Analysis (EDA):** Visualisations (histograms, scatter plots, heatmaps) to understand feature distributions and relationships
* **Statistical Testing:** Hypothesis testing to validate assumptions about production factors and success drivers
* **Feature Engineering:** Transforming and encoding categorical variables, handling missing values, creating target variables
* **Modelling:** Building models to outcomes 
* **Model Evaluation:** Performance metrics appropriate to each model type 
* **Feature Importance Analysis:** Identifying which production attributes have the strongest influence on success 

## Ethical considerations
* The dataset is open-source and publicly available, containing no personal or identifiable data.  
* No legal or privacy issues identified as data was sourced from TMDb’s public Kaggle dataset.

## Dashboard Design
- Power BI Dashboard: Key KPIs, filters, and charts for movie success influencing factors (and genre-specific ones for the Horror dashboard)
- Purpose: Communicate feature importance and success drivers
- Audience: Production companies, investors, and decision-makers who need clear, actionable insights into which factors drive film success
- Note: Dashboard genre focus (Horror) provides a closer look at this genre and its key success drivers

## Unfixed Bugs
* Some missing cast or budget data limited model completeness.  
* Genre classification simplified to one ‘Primary Genre’, which may misrepresent multi-genre films.  
* No critical bugs affecting core ETL, EDA, or model outputs.

## Development Roadmap
* **Challenges:** Handling messy nested JSON (genres, cast, and crew) and missing data across multiple columns.  
* **Strategies:** Iterative cleaning and feature extraction with validation at each stage; using visual and statistical checks for quality.  

* **Next Steps:**  
  - Expand genre-specific dashboards (Crime, Animation, Sci-Fi) for deeper category insights.  
  - Develop a Streamlit app as an accessible, lightweight front-end for the model, allowing users to input film attributes (budget, cast size, genre, language) and receive predicted success and risk factors.  
  - Extend model testing (for example, Random Forest) to compare predictive accuracy against the baseline model.

## Deployment
* Power BI will be used for the final deployment, featuring two reports:  
  - **Overview Dashboard:** Presents overall success drivers, predictive revenue insights, and key production metrics.  
  - **Genre-Specific Dashboard (Horror):** Focuses on performance drivers, trends, and success patterns within the Horror category.  

## Main Data Analysis Libraries

## Main Data Analysis Libraries

- Pandas (for data loading, cleaning, manipulation, and exploratory analysis)
- NumPy (for numerical operations and array handling)
- Matplotlib (for static data visualisations and plots)
- Seaborn (for enhanced statistical visualisations and correlation analysis)
- Plotly (for interactive visualisations and dashboards)
- SciPy (for statistical testing including t-tests and Mann-Whitney U tests)
- Pingouin (for advanced statistical analyses and hypothesis testing)
- Scikit-learn (for preprocessing, model building, evaluation metrics, cross-validation including Logistic Regression and pipelines)
- XGBoost (for gradient boosting regression models and hyperparameter tuning)
- ast (for parsing JSON-like string data such as genre and cast information)


## Credits 

* We received support from our tutors Vasi Pavaloi for resolving project issues and understanding how to complete tasks.
* We reference our course LMS system for help with best practice and code decsions.
* We used Chat GPT 4.0 and GitHub CoPilot to help with problems, explain errors, and explore different ways to write and (or improve) functions and code

### Content 

- The text for the Home page was taken from Wikipedia Article A
- Instructions on how to implement form validation on the Sign-Up page was taken from [Specific YouTube Tutorial](https://www.youtube.com/)
- The icons in the footer were taken from [Font Awesome](https://fontawesome.com/)

### Media

- The photos used on the home and sign-up page are from This Open-Source site
- The images used for the gallery page were taken from this other open-source site

